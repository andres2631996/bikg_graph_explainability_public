{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b2ce61b",
   "metadata": {},
   "source": [
    "# Tutorial on a toy example\n",
    "\n",
    "We will design a graph with two communities influencing the behavior of a central node in a Graph Neural Network on a node prediction use case.\n",
    "\n",
    "The tutorial is divided into two cases:\n",
    "\n",
    "a) All the nodes in one of the communities have labels of almost 1 (0.9), and the nodes in the other community\n",
    "have labels of almost 0 (0.1). The central node is assigned a label of 0.9, and we show how the community with the nodes labelled as 0.9 is the most relevant for the value of 0.9 in the central node, according to XP-GNN.\n",
    "\n",
    "b) We complete the same use case as in a), but now \"flipping\" the labels. The community with low values of 0.9 in a) now has values of 0.1, and viceversa. In this case, we show how the other community is appointed as the most relevant one for\n",
    "the Graph Neural Network explanation, according to XP-GNN.\n",
    "\n",
    "# This notebook focuses on case A\n",
    "\n",
    "\n",
    "# This experiment is a replica of the Experiment in Section 5.1 of \"Community explanations in knowledge graphs with XP-GNN\", by Andrés Martínez Mora, Dimitris Polychronopoulos, Michaël Ughetto, and Sebastian Nilsson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d14aa",
   "metadata": {},
   "source": [
    "# Import libraries for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06d7862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import networkx\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv,Linear\n",
    "from sklearn.metrics import r2_score\n",
    "from torch_geometric.data import Data\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from pathway_explanations.explainer import Explainer, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4172404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "seed = 0\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae65f1",
   "metadata": {},
   "source": [
    "# Set up graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device where to complete computations\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Setup edge index\n",
    "edge_index = torch.tensor([[0,1],[1,0],[1,2],[2,1],[1,3],[3,1],[1,4],[4,1]],dtype=torch.long,\n",
    "                              device=device)\n",
    "edge_index = edge_index.T\n",
    "\n",
    "# Set up community weights and community structure\n",
    "communities = [[0],[2,3,4]]\n",
    "community_names = [\"blue\",\"red\"]\n",
    "\n",
    "# Set node features as normally distributed\n",
    "length = 16 # Feature size\n",
    "features = torch.randn(int(torch.max(edge_index[0]).item())+1,\n",
    "                       length, device=device)\n",
    "\n",
    "node_names = [\"{}\".format(i) for i in range(features.shape[0])]\n",
    "\n",
    "# Design training labels: CASE A\n",
    "Y = torch.tensor([0.9,0.9,0.1,0.1,0.1],dtype=torch.float,\n",
    "                              device=device)\n",
    "\n",
    "# Define train and test mask\n",
    "# Central node is in the test set\n",
    "test_size = 0.2\n",
    "train_mask = torch.rand(Y.shape, device=device)\n",
    "train_mask[train_mask < test_size] = 0\n",
    "train_mask[train_mask > test_size] = 1\n",
    "train_mask = train_mask.bool()\n",
    "train_mask[1] = False # Keep node of interest in testing set\n",
    "test_mask = ~train_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0bbdf8",
   "metadata": {},
   "source": [
    "# Plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc43147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges_nx = [tuple(edge_index[:,i].cpu().numpy()) for i in range(edge_index.shape[-1])]\n",
    "G = networkx.Graph()\n",
    "G.add_edges_from(edges_nx)\n",
    "colors = [\"blue\",\"black\",\"red\",\"red\",\"red\"]\n",
    "\n",
    "plt.figure()\n",
    "networkx.draw(G,node_color=colors,node_size=1000,with_labels=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5fe23d",
   "metadata": {},
   "source": [
    "# Model for training artificial graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c4be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_homo(torch.nn.Module): # Homogeneous GCN\n",
    "    def __init__(self, node_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load hyperparameters\n",
    "        seed = 0\n",
    "        hidden_channels = 8\n",
    "        out_neurons = 1\n",
    "        conv_layers = [16, 8, 8]\n",
    "        fc_layers = [8, 8, 16]\n",
    "\n",
    "        seed,out_neurons = int(seed),int(out_neurons)\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        conv_list,fc_list = [],[]\n",
    "        \n",
    "        for enum_conv_layer,conv_layer in enumerate(conv_layers): # Setup convolutional backbone\n",
    "            assert isinstance(conv_layer,int) or isinstance(conv_layer,float),\"Size of convolutional layer is not numeric\"\n",
    "            conv_layer = abs(int(conv_layer))\n",
    "            \n",
    "            if enum_conv_layer == 0:\n",
    "                conv = GCNConv(node_features,conv_layer)\n",
    "            else:\n",
    "                conv = GCNConv(conv_layers[enum_conv_layer - 1],conv_layer)\n",
    "                \n",
    "            conv_list.append(conv)\n",
    "            conv_list.append(nn.ReLU())\n",
    "            \n",
    "        self.conv = nn.ModuleList(conv_list)\n",
    "        \n",
    "        for enum_fc_layer,fc_layer in enumerate(fc_layers): # Setup linear backbone\n",
    "        \n",
    "            assert isinstance(fc_layer,int) or isinstance(fc_layer,float),\"Size of convolutional layer is not numeric\"\n",
    "        \n",
    "            if enum_fc_layer == (len(fc_layers) - 1): # Last FC layer\n",
    "                lin = Linear(fc_layers[enum_fc_layer],out_neurons)\n",
    "                act = nn.Sigmoid()\n",
    "            else:\n",
    "                lin = Linear(fc_layers[enum_fc_layer],fc_layers[enum_fc_layer + 1])\n",
    "                act = nn.ReLU()\n",
    "            fc_list.append(lin)\n",
    "            fc_list.append(act)\n",
    "            \n",
    "        self.fc = nn.ModuleList(fc_list[:(-1)])\n",
    "        #self.fc = nn.ModuleList(fc_list)\n",
    "        \n",
    "        \n",
    "    def forward(self,x,edge_index):\n",
    "        \n",
    "        for enum_c,c in enumerate(self.conv): # Convolutional backbone\n",
    "            if enum_c % 2 == 0: # Even layer: convolution\n",
    "                x = c(x, edge_index)\n",
    "            else: # Odd layer: activation function\n",
    "                x = c(x)\n",
    "                \n",
    "        for l in self.fc: # Fully-connected backbone\n",
    "            x = l(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1343d1d",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49dbd91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN_homo(\n",
      "  (conv): ModuleList(\n",
      "    (0): GCNConv(16, 16)\n",
      "    (1): ReLU()\n",
      "    (2): GCNConv(16, 8)\n",
      "    (3): ReLU()\n",
      "    (4): GCNConv(8, 8)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (fc): ModuleList(\n",
      "    (0): Linear(8, 8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(8, 16, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(16, 1, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch: 1 // Train loss: 0.3659 // Validation R2: -1.8164\n",
      "Epoch: 2 // Train loss: 0.3361 // Validation R2: -1.5934\n",
      "Epoch: 3 // Train loss: 0.3055 // Validation R2: -1.3649\n",
      "Epoch: 4 // Train loss: 0.2801 // Validation R2: -1.1732\n",
      "Epoch: 5 // Train loss: 0.2626 // Validation R2: -1.0499\n",
      "Epoch: 6 // Train loss: 0.2477 // Validation R2: -0.9345\n",
      "Epoch: 7 // Train loss: 0.2349 // Validation R2: -0.8388\n",
      "Epoch: 8 // Train loss: 0.2236 // Validation R2: -0.7501\n",
      "Epoch: 9 // Train loss: 0.2138 // Validation R2: -0.6647\n",
      "Epoch: 10 // Train loss: 0.2066 // Validation R2: -0.6055\n",
      "Epoch: 11 // Train loss: 0.2005 // Validation R2: -0.5454\n",
      "Epoch: 12 // Train loss: 0.1946 // Validation R2: -0.4861\n",
      "Epoch: 13 // Train loss: 0.189 // Validation R2: -0.4304\n",
      "Epoch: 14 // Train loss: 0.1833 // Validation R2: -0.3709\n",
      "Epoch: 15 // Train loss: 0.1771 // Validation R2: -0.3065\n",
      "Epoch: 16 // Train loss: 0.1703 // Validation R2: -0.2335\n",
      "Epoch: 17 // Train loss: 0.1639 // Validation R2: -0.1617\n",
      "Epoch: 18 // Train loss: 0.1572 // Validation R2: -0.081\n",
      "Epoch: 19 // Train loss: 0.151 // Validation R2: 0.0056\n",
      "Epoch: 20 // Train loss: 0.146 // Validation R2: 0.0918\n",
      "Epoch: 21 // Train loss: 0.1433 // Validation R2: 0.1667\n",
      "Epoch: 22 // Train loss: 0.1438 // Validation R2: 0.2116\n",
      "Epoch: 23 // Train loss: 0.1457 // Validation R2: 0.2266\n",
      "Epoch: 24 // Train loss: 0.1459 // Validation R2: 0.2252\n",
      "Epoch: 25 // Train loss: 0.1438 // Validation R2: 0.2163\n",
      "Epoch: 26 // Train loss: 0.1408 // Validation R2: 0.1988\n",
      "Epoch: 27 // Train loss: 0.1387 // Validation R2: 0.1718\n",
      "Epoch: 28 // Train loss: 0.1375 // Validation R2: 0.14\n",
      "Epoch: 29 // Train loss: 0.1369 // Validation R2: 0.1116\n",
      "Epoch: 30 // Train loss: 0.136 // Validation R2: 0.0947\n",
      "Epoch: 31 // Train loss: 0.1344 // Validation R2: 0.0922\n",
      "Epoch: 32 // Train loss: 0.132 // Validation R2: 0.1023\n",
      "Epoch: 33 // Train loss: 0.1287 // Validation R2: 0.1279\n",
      "Epoch: 34 // Train loss: 0.1248 // Validation R2: 0.1632\n",
      "Epoch: 35 // Train loss: 0.121 // Validation R2: 0.1997\n",
      "Epoch: 36 // Train loss: 0.1176 // Validation R2: 0.2281\n",
      "Epoch: 37 // Train loss: 0.1138 // Validation R2: 0.2453\n",
      "Epoch: 38 // Train loss: 0.1085 // Validation R2: 0.2545\n",
      "Epoch: 39 // Train loss: 0.1022 // Validation R2: 0.2579\n",
      "Epoch: 40 // Train loss: 0.0979 // Validation R2: 0.2608\n",
      "Epoch: 41 // Train loss: 0.092 // Validation R2: 0.281\n",
      "Epoch: 42 // Train loss: 0.0848 // Validation R2: 0.3091\n",
      "Epoch: 43 // Train loss: 0.079 // Validation R2: 0.3231\n",
      "Epoch: 44 // Train loss: 0.0738 // Validation R2: 0.3305\n",
      "Epoch: 45 // Train loss: 0.0676 // Validation R2: 0.3687\n",
      "Epoch: 46 // Train loss: 0.0613 // Validation R2: 0.4279\n",
      "Epoch: 47 // Train loss: 0.055 // Validation R2: 0.4896\n",
      "Epoch: 48 // Train loss: 0.0483 // Validation R2: 0.5517\n",
      "Epoch: 49 // Train loss: 0.0411 // Validation R2: 0.6224\n",
      "Epoch: 50 // Train loss: 0.0339 // Validation R2: 0.6963\n",
      "Epoch: 51 // Train loss: 0.0285 // Validation R2: 0.7604\n",
      "Epoch: 52 // Train loss: 0.026 // Validation R2: 0.8221\n",
      "Epoch: 53 // Train loss: 0.0247 // Validation R2: 0.8487\n",
      "Epoch: 54 // Train loss: 0.0238 // Validation R2: 0.8257\n",
      "Epoch: 55 // Train loss: 0.0245 // Validation R2: 0.7921\n",
      "Epoch: 56 // Train loss: 0.0238 // Validation R2: 0.8429\n",
      "Epoch: 57 // Train loss: 0.0244 // Validation R2: 0.8786\n",
      "Epoch: 58 // Train loss: 0.023 // Validation R2: 0.8391\n",
      "Epoch: 59 // Train loss: 0.0225 // Validation R2: 0.8305\n",
      "Epoch: 60 // Train loss: 0.0212 // Validation R2: 0.8506\n",
      "Epoch: 61 // Train loss: 0.0196 // Validation R2: 0.8801\n",
      "Epoch: 62 // Train loss: 0.0179 // Validation R2: 0.8983\n",
      "Epoch: 63 // Train loss: 0.0159 // Validation R2: 0.9026\n",
      "Epoch: 64 // Train loss: 0.014 // Validation R2: 0.9033\n",
      "Epoch: 65 // Train loss: 0.0124 // Validation R2: 0.9083\n",
      "Epoch: 66 // Train loss: 0.0109 // Validation R2: 0.9254\n",
      "Epoch: 67 // Train loss: 0.0096 // Validation R2: 0.9409\n",
      "Epoch: 68 // Train loss: 0.0083 // Validation R2: 0.9462\n",
      "Epoch: 69 // Train loss: 0.0073 // Validation R2: 0.9478\n",
      "Epoch: 70 // Train loss: 0.008 // Validation R2: 0.9155\n",
      "Epoch: 71 // Train loss: 0.0073 // Validation R2: 0.9315\n",
      "Epoch: 72 // Train loss: 0.0069 // Validation R2: 0.9291\n",
      "Epoch: 73 // Train loss: 0.0068 // Validation R2: 0.9241\n",
      "Epoch: 74 // Train loss: 0.0059 // Validation R2: 0.9343\n",
      "Epoch: 75 // Train loss: 0.0056 // Validation R2: 0.9415\n",
      "Epoch: 76 // Train loss: 0.0047 // Validation R2: 0.9501\n",
      "Epoch: 77 // Train loss: 0.0043 // Validation R2: 0.954\n",
      "Epoch: 78 // Train loss: 0.0039 // Validation R2: 0.9579\n",
      "Epoch: 79 // Train loss: 0.0035 // Validation R2: 0.9649\n",
      "Epoch: 80 // Train loss: 0.0032 // Validation R2: 0.9727\n",
      "Epoch: 81 // Train loss: 0.0031 // Validation R2: 0.9787\n",
      "Epoch: 82 // Train loss: 0.003 // Validation R2: 0.9799\n",
      "Epoch: 83 // Train loss: 0.0029 // Validation R2: 0.975\n",
      "Epoch: 84 // Train loss: 0.0028 // Validation R2: 0.9765\n",
      "Epoch: 85 // Train loss: 0.0026 // Validation R2: 0.9831\n",
      "Epoch: 86 // Train loss: 0.0025 // Validation R2: 0.9874\n",
      "Epoch: 87 // Train loss: 0.0023 // Validation R2: 0.9835\n",
      "Epoch: 88 // Train loss: 0.0021 // Validation R2: 0.9808\n",
      "Epoch: 89 // Train loss: 0.0019 // Validation R2: 0.9843\n",
      "Epoch: 90 // Train loss: 0.0017 // Validation R2: 0.9862\n",
      "Epoch: 91 // Train loss: 0.0016 // Validation R2: 0.9846\n",
      "Epoch: 92 // Train loss: 0.0015 // Validation R2: 0.982\n",
      "Epoch: 93 // Train loss: 0.0014 // Validation R2: 0.9825\n",
      "Epoch: 94 // Train loss: 0.0013 // Validation R2: 0.9844\n",
      "Epoch: 95 // Train loss: 0.0013 // Validation R2: 0.9849\n",
      "Epoch: 96 // Train loss: 0.0012 // Validation R2: 0.9844\n",
      "Epoch: 97 // Train loss: 0.0011 // Validation R2: 0.9843\n",
      "Epoch: 98 // Train loss: 0.001 // Validation R2: 0.9864\n",
      "Epoch: 99 // Train loss: 0.001 // Validation R2: 0.9883\n",
      "Epoch: 100 // Train loss: 0.0009 // Validation R2: 0.9892\n",
      "Epoch: 101 // Train loss: 0.0008 // Validation R2: 0.9894\n",
      "Epoch: 102 // Train loss: 0.0007 // Validation R2: 0.991\n",
      "Epoch: 103 // Train loss: 0.0007 // Validation R2: 0.9931\n",
      "Epoch: 104 // Train loss: 0.0006 // Validation R2: 0.994\n",
      "Epoch: 105 // Train loss: 0.0006 // Validation R2: 0.9937\n",
      "Epoch: 106 // Train loss: 0.0005 // Validation R2: 0.9944\n",
      "Epoch: 107 // Train loss: 0.0005 // Validation R2: 0.996\n",
      "Epoch: 108 // Train loss: 0.0005 // Validation R2: 0.9964\n",
      "Epoch: 109 // Train loss: 0.0004 // Validation R2: 0.9959\n",
      "Epoch: 110 // Train loss: 0.0004 // Validation R2: 0.9963\n",
      "Epoch: 111 // Train loss: 0.0003 // Validation R2: 0.9973\n",
      "Epoch: 112 // Train loss: 0.0003 // Validation R2: 0.9974\n",
      "Epoch: 113 // Train loss: 0.0003 // Validation R2: 0.997\n",
      "Epoch: 114 // Train loss: 0.0002 // Validation R2: 0.9973\n",
      "Epoch: 115 // Train loss: 0.0002 // Validation R2: 0.9978\n",
      "Epoch: 116 // Train loss: 0.0002 // Validation R2: 0.9978\n",
      "Epoch: 117 // Train loss: 0.0002 // Validation R2: 0.9977\n",
      "Epoch: 118 // Train loss: 0.0002 // Validation R2: 0.998\n",
      "Epoch: 119 // Train loss: 0.0002 // Validation R2: 0.9983\n",
      "Epoch: 120 // Train loss: 0.0001 // Validation R2: 0.9983\n",
      "Epoch: 121 // Train loss: 0.0001 // Validation R2: 0.9984\n",
      "Epoch: 122 // Train loss: 0.0001 // Validation R2: 0.9988\n",
      "Epoch: 123 // Train loss: 0.0001 // Validation R2: 0.999\n",
      "Epoch: 124 // Train loss: 0.0001 // Validation R2: 0.999\n",
      "Epoch: 125 // Train loss: 0.0001 // Validation R2: 0.9993\n",
      "Epoch: 126 // Train loss: 0.0001 // Validation R2: 0.9995\n",
      "Epoch: 127 // Train loss: 0.0001 // Validation R2: 0.9995\n",
      "Epoch: 128 // Train loss: 0.0 // Validation R2: 0.9996\n",
      "Epoch: 129 // Train loss: 0.0 // Validation R2: 0.9998\n",
      "Epoch: 130 // Train loss: 0.0 // Validation R2: 0.9998\n",
      "Epoch: 131 // Train loss: 0.0 // Validation R2: 0.9998\n",
      "Epoch: 132 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 133 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 134 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 135 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 136 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 137 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 138 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 139 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 140 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 141 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 142 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 143 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 144 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 145 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 146 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 147 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 148 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 149 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 150 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 151 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 152 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 153 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 154 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 155 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 156 // Train loss: 0.0 // Validation R2: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 157 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 158 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 159 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 160 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 161 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 162 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 163 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 164 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 165 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 166 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 167 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 168 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 169 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 170 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 171 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 172 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 173 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 174 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 175 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 176 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 177 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 178 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 179 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 180 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 181 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 182 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 183 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 184 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 185 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 186 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 187 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 188 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 189 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 190 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 191 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 192 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 193 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 194 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 195 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 196 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 197 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 198 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 199 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 200 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 201 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 202 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 203 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 204 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 205 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 206 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 207 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 208 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 209 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 210 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 211 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 212 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 213 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 214 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 215 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 216 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 217 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 218 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 219 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 220 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 221 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 222 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 223 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 224 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 225 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 226 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 227 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 228 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 229 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 230 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 231 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 232 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 233 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 234 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 235 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 236 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 237 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 238 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 239 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 240 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 241 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 242 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 243 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 244 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 245 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 246 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 247 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 248 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 249 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 250 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 251 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 252 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 253 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 254 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 255 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 256 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 257 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 258 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 259 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 260 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 261 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 262 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 263 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 264 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 265 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 266 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 267 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 268 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 269 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 270 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 271 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 272 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 273 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 274 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 275 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 276 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 277 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 278 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 279 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 280 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 281 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 282 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 283 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 284 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 285 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 286 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 287 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 288 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 289 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 290 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 291 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 292 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 293 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 294 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 295 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 296 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 297 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 298 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 299 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 300 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 301 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 302 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 303 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 304 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 305 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 306 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 307 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 308 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 309 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 310 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 311 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 312 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 313 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 314 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 315 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 316 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 317 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 318 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 319 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 320 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 321 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 322 // Train loss: 0.0 // Validation R2: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 323 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 324 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 325 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 326 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 327 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 328 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 329 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 330 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 331 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 332 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 333 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 334 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 335 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 336 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 337 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 338 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 339 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 340 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 341 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 342 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 343 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 344 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 345 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 346 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 347 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 348 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 349 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 350 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 351 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 352 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 353 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 354 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 355 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 356 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 357 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 358 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 359 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 360 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 361 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 362 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 363 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 364 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 365 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 366 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 367 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 368 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 369 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 370 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 371 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 372 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 373 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 374 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 375 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 376 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 377 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 378 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 379 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 380 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 381 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 382 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 383 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 384 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 385 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 386 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 387 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 388 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 389 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 390 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 391 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 392 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 393 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 394 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 395 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 396 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 397 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 398 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 399 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 400 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 401 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 402 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 403 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 404 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 405 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 406 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 407 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 408 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 409 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 410 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 411 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 412 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 413 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 414 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 415 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 416 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 417 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 418 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 419 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 420 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 421 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 422 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 423 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 424 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 425 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 426 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 427 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 428 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 429 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 430 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 431 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 432 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 433 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 434 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 435 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 436 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 437 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 438 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 439 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 440 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 441 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 442 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 443 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 444 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 445 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 446 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 447 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 448 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 449 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 450 // Train loss: 0.0 // Validation R2: 0.9998\n",
      "Epoch: 451 // Train loss: 0.0001 // Validation R2: 0.9995\n",
      "Epoch: 452 // Train loss: 0.0001 // Validation R2: 0.9991\n",
      "Epoch: 453 // Train loss: 0.0002 // Validation R2: 0.9983\n",
      "Epoch: 454 // Train loss: 0.0005 // Validation R2: 0.9954\n",
      "Epoch: 455 // Train loss: 0.001 // Validation R2: 0.9913\n",
      "Epoch: 456 // Train loss: 0.0025 // Validation R2: 0.9777\n",
      "Epoch: 457 // Train loss: 0.002 // Validation R2: 0.9831\n",
      "Epoch: 458 // Train loss: 0.0011 // Validation R2: 0.9892\n",
      "Epoch: 459 // Train loss: 0.0 // Validation R2: 0.9995\n",
      "Epoch: 460 // Train loss: 0.0012 // Validation R2: 0.9922\n",
      "Epoch: 461 // Train loss: 0.0013 // Validation R2: 0.9856\n",
      "Epoch: 462 // Train loss: 0.0 // Validation R2: 0.9998\n",
      "Epoch: 463 // Train loss: 0.0011 // Validation R2: 0.9933\n",
      "Epoch: 464 // Train loss: 0.001 // Validation R2: 0.9893\n",
      "Epoch: 465 // Train loss: 0.0001 // Validation R2: 0.9988\n",
      "Epoch: 466 // Train loss: 0.0011 // Validation R2: 0.9929\n",
      "Epoch: 467 // Train loss: 0.0005 // Validation R2: 0.9944\n",
      "Epoch: 468 // Train loss: 0.0003 // Validation R2: 0.9968\n",
      "Epoch: 469 // Train loss: 0.0009 // Validation R2: 0.9939\n",
      "Epoch: 470 // Train loss: 0.0001 // Validation R2: 0.9988\n",
      "Epoch: 471 // Train loss: 0.0004 // Validation R2: 0.9955\n",
      "Epoch: 472 // Train loss: 0.0004 // Validation R2: 0.9973\n",
      "Epoch: 473 // Train loss: 0.0 // Validation R2: 0.9997\n",
      "Epoch: 474 // Train loss: 0.0004 // Validation R2: 0.996\n",
      "Epoch: 475 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 476 // Train loss: 0.0003 // Validation R2: 0.9973\n",
      "Epoch: 477 // Train loss: 0.0003 // Validation R2: 0.9975\n",
      "Epoch: 478 // Train loss: 0.0001 // Validation R2: 0.9996\n",
      "Epoch: 479 // Train loss: 0.0004 // Validation R2: 0.9961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 480 // Train loss: 0.0001 // Validation R2: 0.9992\n",
      "Epoch: 481 // Train loss: 0.0002 // Validation R2: 0.9986\n",
      "Epoch: 482 // Train loss: 0.0002 // Validation R2: 0.9981\n",
      "Epoch: 483 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 484 // Train loss: 0.0002 // Validation R2: 0.9983\n",
      "Epoch: 485 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 486 // Train loss: 0.0001 // Validation R2: 0.9992\n",
      "Epoch: 487 // Train loss: 0.0001 // Validation R2: 0.9991\n",
      "Epoch: 488 // Train loss: 0.0 // Validation R2: 0.9997\n",
      "Epoch: 489 // Train loss: 0.0001 // Validation R2: 0.9992\n",
      "Epoch: 490 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 491 // Train loss: 0.0001 // Validation R2: 0.9991\n",
      "Epoch: 492 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 493 // Train loss: 0.0 // Validation R2: 0.9997\n",
      "Epoch: 494 // Train loss: 0.0 // Validation R2: 0.9995\n",
      "Epoch: 495 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 496 // Train loss: 0.0001 // Validation R2: 0.9996\n",
      "Epoch: 497 // Train loss: 0.0 // Validation R2: 1.0\n",
      "Epoch: 498 // Train loss: 0.0 // Validation R2: 0.9996\n",
      "Epoch: 499 // Train loss: 0.0 // Validation R2: 0.9999\n",
      "Epoch: 500 // Train loss: 0.0 // Validation R2: 0.9999\n"
     ]
    }
   ],
   "source": [
    "# Call architecture\n",
    "model = GCN_homo(features.shape[-1]).to(device)\n",
    "print(model)\n",
    "\n",
    "# Load optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    H = model(features, \n",
    "              edge_index)\n",
    "    \n",
    "    # Use MSE as loss for weight prediction\n",
    "    loss = F.mse_loss(H.flatten(), \n",
    "                      Y.flatten())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    r2_val = r2_score(Y[test_mask].cpu().detach().numpy(),\n",
    "                      H[test_mask].cpu().detach().numpy())\n",
    "    \n",
    "    print(\"Epoch:\", epoch+1, \"// Train loss:\", round(loss.item(),4),\"// Validation R2:\", round(r2_val,4)) \n",
    "    \n",
    "    val_old = r2_val    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9784c4af",
   "metadata": {},
   "source": [
    "# Set up hyperparameters for explanation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d3d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_params = {\n",
    "                        \"seed\": seed,\n",
    "                        \"interpret_samples\": 20,\n",
    "                        \"epochs\": 50,\n",
    "                        \"optimizer\": \"adam\",\n",
    "                        \"lr\": 0.01,\n",
    "                        \"lr_patience\": 10,\n",
    "                        \"l1_lambda\": 1e-4\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb80ce6",
   "metadata": {},
   "source": [
    "# Explanation pipeline execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dce14ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time ellapsed for explanation for node 1: 5.3734sec\n"
     ]
    }
   ],
   "source": [
    "query_node = \"1\" # The central node is the node in position \"10\"\n",
    "repeats = 10 # Number of initializations to be averaged for the pipeline\n",
    "query_type = None\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Define Explainer object\n",
    "pipeline = Explainer(\n",
    "        features,\n",
    "        edge_index,\n",
    "        model.float(),\n",
    "        explanation_params,\n",
    "        node_names,\n",
    "        communities,\n",
    "        community_names,\n",
    "        query_type,\n",
    "        problem=\"node_prediction\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Run Explainer object\n",
    "node_df, community_df = pipeline.run(query_node, repeats)\n",
    "\n",
    "print(\"Time ellapsed for explanation for node {}: {}sec\".format(query_node,round(time.time() - t1, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5b0dcd",
   "metadata": {},
   "source": [
    "# Result checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7d86f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>0.064897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>0.046919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score\n",
       "name          \n",
       "blue  0.064897\n",
       "red   0.046919"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Community ranking\n",
    "community_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb886c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config_value_mean</th>\n",
       "      <th>config_value_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064897</td>\n",
       "      <td>0.024318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064852</td>\n",
       "      <td>0.014449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056853</td>\n",
       "      <td>0.020904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019053</td>\n",
       "      <td>0.036981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005563</td>\n",
       "      <td>0.008636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      config_value_mean  config_value_std\n",
       "name                                     \n",
       "0              0.064897          0.024318\n",
       "4              0.064852          0.014449\n",
       "2              0.056853          0.020904\n",
       "3              0.019053          0.036981\n",
       "1              0.005563          0.008636"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Node ranking\n",
    "node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdab236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
